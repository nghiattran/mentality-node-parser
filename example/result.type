units: Positive integer, dimensionality of the output space.

activation: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. "linear" activation: a(x) = x).

use_bias: Boolean, whether the layer uses a bias vector.

kernel_initializer: Initializer for the kernel weights matrix (see initializers).
bias_initializer: Initializer for the bias vector (see initializers).
kernel_regularizer: Regularizer function applied to the kernel weights matrix (see regularizer).
bias_regularizer: Regularizer function applied to the bias vector (see regularizer).
activity_regularizer: Regularizer function applied to the output of the layer (its "activation"). (see regularizer).
kernel_constraint: Constraint function applied to the kernel weights matrix (see constraints).
bias_constraint: Constraint function applied to the bias vector (see constraints).


Node {
  required units {
    type: integer
    min: 1
    description: Positive integer, dimensionality of the output space.
activation: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. "linear" activation: a(x) = x).
  }
  optional activation {
    type: string
    default: 'relu'
    description: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. "linear" activation: a(x) = x).
  }
  optional use_bias {
    type: bool
    default: true
    description: Boolean, whether the layer uses a bias vector.
  }
}